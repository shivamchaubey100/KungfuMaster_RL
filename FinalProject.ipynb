{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1545ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OrderEnforcing<PassiveEnvChecker<AtariEnv<ALE/KungFuMaster-v5>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.11.1+2750686)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"ALE/KungFuMaster-v5\", render_mode=\"rgb_array\")\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d622542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gymnasium/wrappers/rendering.py:296: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/shivam/Documents/KungfuMaster_SOC/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Reward: 300.00, Epsilon: 0.999\n",
      "Episode: 2, Reward: 500.00, Epsilon: 0.998\n",
      "Episode: 3, Reward: 100.00, Epsilon: 0.998\n",
      "Episode: 4, Reward: 700.00, Epsilon: 0.997\n",
      "Episode: 5, Reward: 400.00, Epsilon: 0.996\n",
      "Episode: 6, Reward: 500.00, Epsilon: 0.995\n",
      "Episode: 7, Reward: 400.00, Epsilon: 0.995\n",
      "Episode: 8, Reward: 0.00, Epsilon: 0.994\n",
      "Episode: 9, Reward: 1500.00, Epsilon: 0.993\n",
      "Episode: 10, Reward: 200.00, Epsilon: 0.992\n",
      "Episode: 11, Reward: 300.00, Epsilon: 0.991\n",
      "Episode: 12, Reward: 700.00, Epsilon: 0.990\n",
      "Episode: 13, Reward: 900.00, Epsilon: 0.989\n",
      "Episode: 14, Reward: 300.00, Epsilon: 0.989\n",
      "Episode: 15, Reward: 900.00, Epsilon: 0.988\n",
      "Episode: 16, Reward: 800.00, Epsilon: 0.987\n",
      "Episode: 17, Reward: 300.00, Epsilon: 0.986\n",
      "Episode: 18, Reward: 200.00, Epsilon: 0.985\n",
      "Episode: 19, Reward: 800.00, Epsilon: 0.984\n",
      "Episode: 20, Reward: 600.00, Epsilon: 0.983\n",
      "Episode: 21, Reward: 300.00, Epsilon: 0.982\n",
      "Episode: 22, Reward: 300.00, Epsilon: 0.982\n",
      "Episode: 23, Reward: 700.00, Epsilon: 0.981\n",
      "Episode: 24, Reward: 800.00, Epsilon: 0.980\n",
      "Episode: 25, Reward: 300.00, Epsilon: 0.979\n",
      "Episode: 26, Reward: 400.00, Epsilon: 0.978\n",
      "Episode: 27, Reward: 700.00, Epsilon: 0.977\n",
      "Episode: 28, Reward: 200.00, Epsilon: 0.976\n",
      "Episode: 29, Reward: 600.00, Epsilon: 0.975\n",
      "Episode: 30, Reward: 800.00, Epsilon: 0.974\n",
      "Episode: 31, Reward: 200.00, Epsilon: 0.973\n",
      "Episode: 32, Reward: 300.00, Epsilon: 0.972\n",
      "Episode: 33, Reward: 500.00, Epsilon: 0.971\n",
      "Episode: 34, Reward: 500.00, Epsilon: 0.970\n",
      "Episode: 35, Reward: 500.00, Epsilon: 0.969\n",
      "Episode: 36, Reward: 600.00, Epsilon: 0.968\n",
      "Episode: 37, Reward: 900.00, Epsilon: 0.967\n",
      "Episode: 38, Reward: 400.00, Epsilon: 0.967\n",
      "Episode: 39, Reward: 600.00, Epsilon: 0.966\n",
      "Episode: 40, Reward: 400.00, Epsilon: 0.965\n",
      "Episode: 41, Reward: 500.00, Epsilon: 0.964\n",
      "Episode: 42, Reward: 300.00, Epsilon: 0.963\n",
      "Episode: 43, Reward: 800.00, Epsilon: 0.962\n",
      "Episode: 44, Reward: 0.00, Epsilon: 0.961\n",
      "Episode: 45, Reward: 0.00, Epsilon: 0.961\n",
      "Episode: 46, Reward: 900.00, Epsilon: 0.960\n",
      "Episode: 47, Reward: 1300.00, Epsilon: 0.959\n",
      "Episode: 48, Reward: 600.00, Epsilon: 0.958\n",
      "Episode: 49, Reward: 800.00, Epsilon: 0.957\n",
      "Episode: 50, Reward: 1800.00, Epsilon: 0.956\n",
      "Episode: 51, Reward: 800.00, Epsilon: 0.955\n",
      "Episode: 52, Reward: 800.00, Epsilon: 0.954\n",
      "Episode: 53, Reward: 0.00, Epsilon: 0.953\n",
      "Episode: 54, Reward: 600.00, Epsilon: 0.952\n",
      "Episode: 55, Reward: 900.00, Epsilon: 0.951\n",
      "Episode: 56, Reward: 0.00, Epsilon: 0.951\n",
      "Episode: 57, Reward: 400.00, Epsilon: 0.950\n",
      "Episode: 58, Reward: 100.00, Epsilon: 0.949\n",
      "Episode: 59, Reward: 600.00, Epsilon: 0.948\n",
      "Episode: 60, Reward: 1300.00, Epsilon: 0.947\n",
      "Episode: 61, Reward: 700.00, Epsilon: 0.946\n",
      "Episode: 62, Reward: 400.00, Epsilon: 0.946\n",
      "Episode: 63, Reward: 1300.00, Epsilon: 0.945\n",
      "Episode: 64, Reward: 400.00, Epsilon: 0.944\n",
      "Episode: 65, Reward: 400.00, Epsilon: 0.943\n",
      "Episode: 66, Reward: 200.00, Epsilon: 0.942\n",
      "Episode: 67, Reward: 100.00, Epsilon: 0.941\n",
      "Episode: 68, Reward: 200.00, Epsilon: 0.940\n",
      "Episode: 69, Reward: 1000.00, Epsilon: 0.939\n",
      "Episode: 70, Reward: 400.00, Epsilon: 0.938\n",
      "Episode: 71, Reward: 300.00, Epsilon: 0.937\n",
      "Episode: 72, Reward: 600.00, Epsilon: 0.937\n",
      "Episode: 73, Reward: 900.00, Epsilon: 0.936\n",
      "Episode: 74, Reward: 500.00, Epsilon: 0.935\n",
      "Episode: 75, Reward: 700.00, Epsilon: 0.934\n",
      "Episode: 76, Reward: 100.00, Epsilon: 0.933\n",
      "Episode: 77, Reward: 700.00, Epsilon: 0.932\n",
      "Episode: 78, Reward: 700.00, Epsilon: 0.931\n",
      "Episode: 79, Reward: 1100.00, Epsilon: 0.930\n",
      "Episode: 80, Reward: 400.00, Epsilon: 0.929\n",
      "Episode: 81, Reward: 300.00, Epsilon: 0.928\n",
      "Episode: 82, Reward: 300.00, Epsilon: 0.927\n",
      "Episode: 83, Reward: 900.00, Epsilon: 0.927\n",
      "Episode: 84, Reward: 500.00, Epsilon: 0.926\n",
      "Episode: 85, Reward: 900.00, Epsilon: 0.925\n",
      "Episode: 86, Reward: 500.00, Epsilon: 0.924\n",
      "Episode: 87, Reward: 200.00, Epsilon: 0.923\n",
      "Episode: 88, Reward: 700.00, Epsilon: 0.922\n",
      "Episode: 89, Reward: 500.00, Epsilon: 0.921\n",
      "Episode: 90, Reward: 1400.00, Epsilon: 0.920\n",
      "Episode: 91, Reward: 800.00, Epsilon: 0.919\n",
      "Episode: 92, Reward: 1700.00, Epsilon: 0.918\n",
      "Episode: 93, Reward: 600.00, Epsilon: 0.918\n",
      "Episode: 94, Reward: 700.00, Epsilon: 0.917\n",
      "Episode: 95, Reward: 300.00, Epsilon: 0.916\n",
      "Episode: 96, Reward: 1100.00, Epsilon: 0.915\n",
      "Episode: 97, Reward: 300.00, Epsilon: 0.914\n",
      "Episode: 98, Reward: 1200.00, Epsilon: 0.913\n",
      "Episode: 99, Reward: 600.00, Epsilon: 0.912\n",
      "Episode: 100, Reward: 800.00, Epsilon: 0.911\n",
      "Episode: 101, Reward: 600.00, Epsilon: 0.910\n",
      "Episode: 102, Reward: 200.00, Epsilon: 0.910\n",
      "Episode: 103, Reward: 1100.00, Epsilon: 0.909\n",
      "Episode: 104, Reward: 500.00, Epsilon: 0.908\n",
      "Episode: 105, Reward: 400.00, Epsilon: 0.907\n",
      "Episode: 106, Reward: 300.00, Epsilon: 0.906\n",
      "Episode: 107, Reward: 1100.00, Epsilon: 0.905\n",
      "Episode: 108, Reward: 1100.00, Epsilon: 0.904\n",
      "Episode: 109, Reward: 500.00, Epsilon: 0.903\n",
      "Episode: 110, Reward: 700.00, Epsilon: 0.902\n",
      "Episode: 111, Reward: 1000.00, Epsilon: 0.901\n",
      "Episode: 112, Reward: 800.00, Epsilon: 0.899\n",
      "Episode: 113, Reward: 700.00, Epsilon: 0.898\n",
      "Episode: 114, Reward: 1600.00, Epsilon: 0.897\n",
      "Episode: 115, Reward: 400.00, Epsilon: 0.896\n",
      "Episode: 116, Reward: 1100.00, Epsilon: 0.895\n",
      "Episode: 117, Reward: 400.00, Epsilon: 0.894\n",
      "Episode: 118, Reward: 800.00, Epsilon: 0.893\n",
      "Episode: 119, Reward: 600.00, Epsilon: 0.893\n",
      "Episode: 120, Reward: 900.00, Epsilon: 0.891\n",
      "Episode: 121, Reward: 200.00, Epsilon: 0.891\n",
      "Episode: 122, Reward: 600.00, Epsilon: 0.890\n",
      "Episode: 123, Reward: 600.00, Epsilon: 0.889\n",
      "Episode: 124, Reward: 1100.00, Epsilon: 0.888\n",
      "Episode: 125, Reward: 1000.00, Epsilon: 0.887\n",
      "Episode: 126, Reward: 900.00, Epsilon: 0.886\n",
      "Episode: 127, Reward: 500.00, Epsilon: 0.885\n",
      "Episode: 128, Reward: 1000.00, Epsilon: 0.884\n",
      "Episode: 129, Reward: 700.00, Epsilon: 0.883\n",
      "Episode: 130, Reward: 1500.00, Epsilon: 0.882\n",
      "Episode: 131, Reward: 1500.00, Epsilon: 0.881\n",
      "Episode: 132, Reward: 400.00, Epsilon: 0.880\n",
      "Episode: 133, Reward: 200.00, Epsilon: 0.879\n",
      "Episode: 134, Reward: 500.00, Epsilon: 0.878\n",
      "Episode: 135, Reward: 200.00, Epsilon: 0.878\n",
      "Episode: 136, Reward: 900.00, Epsilon: 0.877\n",
      "Episode: 137, Reward: 1100.00, Epsilon: 0.876\n",
      "Episode: 138, Reward: 500.00, Epsilon: 0.875\n",
      "Episode: 139, Reward: 1300.00, Epsilon: 0.874\n",
      "Episode: 140, Reward: 300.00, Epsilon: 0.873\n",
      "Episode: 141, Reward: 800.00, Epsilon: 0.872\n",
      "Episode: 142, Reward: 600.00, Epsilon: 0.871\n",
      "Episode: 143, Reward: 500.00, Epsilon: 0.869\n",
      "Episode: 144, Reward: 1800.00, Epsilon: 0.868\n",
      "Episode: 145, Reward: 1200.00, Epsilon: 0.867\n",
      "Episode: 146, Reward: 300.00, Epsilon: 0.866\n",
      "Episode: 147, Reward: 300.00, Epsilon: 0.866\n",
      "Episode: 148, Reward: 200.00, Epsilon: 0.865\n",
      "Episode: 149, Reward: 500.00, Epsilon: 0.864\n",
      "Episode: 150, Reward: 1000.00, Epsilon: 0.863\n",
      "Episode: 151, Reward: 700.00, Epsilon: 0.862\n",
      "Episode: 152, Reward: 800.00, Epsilon: 0.861\n",
      "Episode: 153, Reward: 1200.00, Epsilon: 0.860\n",
      "Episode: 154, Reward: 100.00, Epsilon: 0.859\n",
      "Episode: 155, Reward: 1900.00, Epsilon: 0.858\n",
      "Episode: 156, Reward: 1100.00, Epsilon: 0.857\n",
      "Episode: 157, Reward: 300.00, Epsilon: 0.856\n",
      "Episode: 158, Reward: 200.00, Epsilon: 0.855\n",
      "Episode: 159, Reward: 200.00, Epsilon: 0.855\n",
      "Episode: 160, Reward: 500.00, Epsilon: 0.854\n",
      "Episode: 161, Reward: 1000.00, Epsilon: 0.853\n",
      "Episode: 162, Reward: 1100.00, Epsilon: 0.851\n",
      "Episode: 163, Reward: 900.00, Epsilon: 0.851\n",
      "Episode: 164, Reward: 100.00, Epsilon: 0.850\n",
      "Episode: 165, Reward: 700.00, Epsilon: 0.849\n",
      "Episode: 166, Reward: 400.00, Epsilon: 0.848\n",
      "Episode: 167, Reward: 600.00, Epsilon: 0.847\n",
      "Episode: 168, Reward: 1000.00, Epsilon: 0.846\n",
      "Episode: 169, Reward: 900.00, Epsilon: 0.845\n",
      "Episode: 170, Reward: 900.00, Epsilon: 0.844\n",
      "Episode: 171, Reward: 600.00, Epsilon: 0.843\n",
      "Episode: 172, Reward: 700.00, Epsilon: 0.842\n",
      "Episode: 173, Reward: 900.00, Epsilon: 0.841\n",
      "Episode: 174, Reward: 700.00, Epsilon: 0.840\n",
      "Episode: 175, Reward: 600.00, Epsilon: 0.839\n",
      "Episode: 176, Reward: 900.00, Epsilon: 0.838\n",
      "Episode: 177, Reward: 700.00, Epsilon: 0.837\n",
      "Episode: 178, Reward: 600.00, Epsilon: 0.837\n",
      "Episode: 179, Reward: 1500.00, Epsilon: 0.836\n",
      "Episode: 180, Reward: 600.00, Epsilon: 0.835\n",
      "Episode: 181, Reward: 1300.00, Epsilon: 0.834\n",
      "Episode: 182, Reward: 1700.00, Epsilon: 0.833\n",
      "Episode: 183, Reward: 300.00, Epsilon: 0.832\n",
      "Episode: 184, Reward: 1700.00, Epsilon: 0.831\n",
      "Episode: 185, Reward: 800.00, Epsilon: 0.830\n",
      "Episode: 186, Reward: 200.00, Epsilon: 0.829\n",
      "Episode: 187, Reward: 1200.00, Epsilon: 0.828\n",
      "Episode: 188, Reward: 500.00, Epsilon: 0.827\n",
      "Episode: 189, Reward: 800.00, Epsilon: 0.826\n",
      "Episode: 190, Reward: 1200.00, Epsilon: 0.825\n",
      "Episode: 191, Reward: 600.00, Epsilon: 0.824\n",
      "Episode: 192, Reward: 200.00, Epsilon: 0.824\n",
      "Episode: 193, Reward: 300.00, Epsilon: 0.822\n",
      "Episode: 194, Reward: 1200.00, Epsilon: 0.821\n",
      "Episode: 195, Reward: 1200.00, Epsilon: 0.820\n",
      "Episode: 196, Reward: 800.00, Epsilon: 0.820\n",
      "Episode: 197, Reward: 1600.00, Epsilon: 0.819\n",
      "Episode: 198, Reward: 300.00, Epsilon: 0.818\n",
      "Episode: 199, Reward: 600.00, Epsilon: 0.817\n",
      "Episode: 200, Reward: 1200.00, Epsilon: 0.816\n",
      "Episode: 201, Reward: 900.00, Epsilon: 0.815\n",
      "Episode: 202, Reward: 500.00, Epsilon: 0.814\n",
      "Episode: 203, Reward: 1000.00, Epsilon: 0.813\n",
      "Episode: 204, Reward: 700.00, Epsilon: 0.812\n",
      "Episode: 205, Reward: 1100.00, Epsilon: 0.811\n",
      "Episode: 206, Reward: 2300.00, Epsilon: 0.809\n",
      "Episode: 207, Reward: 500.00, Epsilon: 0.808\n",
      "Episode: 208, Reward: 300.00, Epsilon: 0.807\n",
      "Episode: 209, Reward: 1200.00, Epsilon: 0.806\n",
      "Episode: 210, Reward: 1000.00, Epsilon: 0.805\n",
      "Episode: 211, Reward: 1500.00, Epsilon: 0.804\n",
      "Episode: 212, Reward: 400.00, Epsilon: 0.803\n",
      "Episode: 213, Reward: 1300.00, Epsilon: 0.802\n",
      "Episode: 214, Reward: 1000.00, Epsilon: 0.801\n",
      "Episode: 215, Reward: 900.00, Epsilon: 0.800\n",
      "Episode: 216, Reward: 700.00, Epsilon: 0.799\n",
      "Episode: 217, Reward: 1200.00, Epsilon: 0.799\n",
      "Episode: 218, Reward: 900.00, Epsilon: 0.797\n",
      "Episode: 219, Reward: 400.00, Epsilon: 0.797\n",
      "Episode: 220, Reward: 1200.00, Epsilon: 0.796\n",
      "Episode: 221, Reward: 1400.00, Epsilon: 0.795\n",
      "Episode: 222, Reward: 1400.00, Epsilon: 0.794\n",
      "Episode: 223, Reward: 400.00, Epsilon: 0.792\n",
      "Episode: 224, Reward: 1000.00, Epsilon: 0.791\n",
      "Episode: 225, Reward: 300.00, Epsilon: 0.791\n",
      "Episode: 226, Reward: 600.00, Epsilon: 0.790\n",
      "Episode: 227, Reward: 1100.00, Epsilon: 0.789\n",
      "Episode: 228, Reward: 1800.00, Epsilon: 0.787\n",
      "Episode: 229, Reward: 1100.00, Epsilon: 0.786\n",
      "Episode: 230, Reward: 400.00, Epsilon: 0.785\n",
      "Episode: 231, Reward: 1700.00, Epsilon: 0.784\n",
      "Episode: 232, Reward: 800.00, Epsilon: 0.784\n",
      "Episode: 233, Reward: 1300.00, Epsilon: 0.783\n",
      "Episode: 234, Reward: 600.00, Epsilon: 0.782\n",
      "Episode: 235, Reward: 800.00, Epsilon: 0.781\n",
      "Episode: 236, Reward: 300.00, Epsilon: 0.780\n",
      "Episode: 237, Reward: 600.00, Epsilon: 0.779\n",
      "Episode: 238, Reward: 700.00, Epsilon: 0.778\n",
      "Episode: 239, Reward: 500.00, Epsilon: 0.777\n",
      "Episode: 240, Reward: 700.00, Epsilon: 0.776\n",
      "Episode: 241, Reward: 900.00, Epsilon: 0.775\n",
      "Episode: 242, Reward: 1500.00, Epsilon: 0.774\n",
      "Episode: 243, Reward: 800.00, Epsilon: 0.773\n",
      "Episode: 244, Reward: 600.00, Epsilon: 0.772\n",
      "Episode: 245, Reward: 1400.00, Epsilon: 0.771\n",
      "Episode: 246, Reward: 1300.00, Epsilon: 0.770\n",
      "Episode: 247, Reward: 900.00, Epsilon: 0.769\n",
      "Episode: 248, Reward: 500.00, Epsilon: 0.768\n",
      "Episode: 249, Reward: 700.00, Epsilon: 0.767\n",
      "Episode: 250, Reward: 800.00, Epsilon: 0.766\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "from memory import ReplayBuffer\n",
    "from agent import DQNAgent\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    # grayscale + resize + normalize\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    return resized.astype(np.float32) / 255.0\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    frame = preprocess_frame(state)\n",
    "    if is_new_episode:\n",
    "        stacked_frames = deque([np.zeros((84,84), dtype=np.float32) for _ in range(4)], maxlen=4)\n",
    "        for _ in range(4):\n",
    "            stacked_frames.append(frame)\n",
    "    else:\n",
    "        stacked_frames.append(frame)\n",
    "    return np.stack(stacked_frames, axis=2), stacked_frames\n",
    "\n",
    "def train(\n",
    "    env_name=\"ALE/KungFuMaster-v5\",\n",
    "    episodes=250,\n",
    "    max_steps=5000,\n",
    "    buffer_size=100000,\n",
    "    batch_size=32,\n",
    "):\n",
    "    env = RecordVideo(\n",
    "    gym.make(env_name, render_mode=\"rgb_array\"),\n",
    "    video_folder=\"videos\",\n",
    "    episode_trigger=lambda ep: True,\n",
    ")\n",
    "    num_actions = env.action_space.n\n",
    "    input_shape = (84, 84, 4)\n",
    "\n",
    "    agent = DQNAgent(input_shape, num_actions)\n",
    "    memory = ReplayBuffer(buffer_size, batch_size)\n",
    "\n",
    "    total_step = 0\n",
    "    for ep in range(1, episodes+1):\n",
    "        state, _ = env.reset()\n",
    "        stacked_frames = None\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        ep_reward = 0\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            next_state_proc, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "\n",
    "            memory.add(state, action, reward, next_state_proc, done)\n",
    "            state = next_state_proc\n",
    "            ep_reward += reward\n",
    "            total_step += 1\n",
    "            agent.step_count = total_step\n",
    "\n",
    "            # train once buffer filled\n",
    "            if len(memory) >= batch_size:\n",
    "                batch = memory.sample()\n",
    "                loss = agent.train_step(batch)\n",
    "                agent.update_epsilon()\n",
    "                agent.maybe_update_target()\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode: {ep}, Reward: {ep_reward:.2f}, Epsilon: {agent.epsilon:.3f}\")\n",
    "        \n",
    "        if ep % 20 == 0:\n",
    "            agent.model.save_weights(f\"checkpoints/dqn_ep{ep}.weights.h5\")\n",
    "            agent.target_model.save_weights(f\"checkpoints/dqn_ep{ep}.weights.h5\")\n",
    "            agent.model.save(f\"checkpoints/dqn_ep{ep}.keras\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba855ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gymnasium/wrappers/rendering.py:296: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/shivam/Documents/KungfuMaster_SOC/Evaluation_videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Episode 1: Total Reward = 2400.0\n",
      "Evaluation Episode 2: Total Reward = 2600.0\n",
      "Evaluation Episode 3: Total Reward = 2100.0\n",
      "Evaluation Episode 4: Total Reward = 3100.0\n",
      "Evaluation Episode 5: Total Reward = 1400.0\n",
      "Evaluation Episode 6: Total Reward = 3800.0\n",
      "Evaluation Episode 7: Total Reward = 3200.0\n",
      "Evaluation Episode 8: Total Reward = 1700.0\n",
      "Evaluation Episode 9: Total Reward = 6000.0\n",
      "Evaluation Episode 10: Total Reward = 1700.0\n"
     ]
    }
   ],
   "source": [
    "env = RecordVideo(\n",
    "    gym.make(\"ALE/KungFuMaster-v5\", render_mode=\"rgb_array\"),\n",
    "    video_folder=\"Evaluation_videos\",\n",
    "    episode_trigger=lambda ep: True,  # record every episode\n",
    ")\n",
    "num_actions = env.action_space.n\n",
    "input_shape = (84, 84, 4)\n",
    "\n",
    "# --- Load DQN Agent and Trained Weights ---\n",
    "agent = DQNAgent(input_shape, num_actions)\n",
    "agent.model.load_weights(\"checkpoints/dqn_ep240.weights.h5\")\n",
    "agent.target_model.load_weights(\"checkpoints/dqn_ep240.weights.h5\")\n",
    "agent.epsilon = 0.0  # pure greedy during evaluation\n",
    "\n",
    "# --- Run Evaluation Episode ---\n",
    "episodes_to_record = 10\n",
    "for ep in range(episodes_to_record):\n",
    "    state, _ = env.reset()\n",
    "    stacked_frames = None\n",
    "    state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "        total_reward += reward\n",
    "\n",
    "    print(f\"Evaluation Episode {ep+1}: Total Reward = {total_reward:.1f}\")\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
